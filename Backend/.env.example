# Database
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/jira_ai_db

# Redis
REDIS_URL=redis://localhost:6379/0

# OpenAI / LLM Configuration
# Supports: OpenAI, DeepSeek, or any OpenAI-compatible API

# For OpenAI (default):
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_API_BASE=
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_TEMPERATURE=0.7

# For DeepSeek (uncomment and use these instead):
# OPENAI_API_KEY=your_deepseek_api_key_here
# OPENAI_API_BASE=https://api.deepseek.com
# OPENAI_MODEL=deepseek-chat
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small
# OPENAI_TEMPERATURE=0.7

# For local models (e.g., Ollama, LM Studio):
# OPENAI_API_KEY=not-needed
# OPENAI_API_BASE=http://localhost:11434/v1
# OPENAI_MODEL=llama2
# OPENAI_EMBEDDING_MODEL=nomic-embed-text
# OPENAI_TEMPERATURE=0.7

# Jira
JIRA_URL=https://your-domain.atlassian.net
JIRA_EMAIL=your-email@example.com
JIRA_API_TOKEN=your_jira_api_token_here
JIRA_PROJECT_KEY=PROJ

# Pinecone (Vector Database)
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=your_pinecone_environment
PINECONE_INDEX_NAME=jira-ai-stories

# Application
APP_NAME=Jira AI Assistant
APP_VERSION=1.0.0
DEBUG=True
SECRET_KEY=your_secret_key_here_change_in_production

# CORS
CORS_ORIGINS=http://localhost:4200,http://localhost:3000

# Celery
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Capacity Sync
CAPACITY_SYNC_INTERVAL=900  # 15 minutes in seconds

# Assignment
MAX_ASSIGNMENT_ATTEMPTS=3
ASSIGNMENT_QUEUE_PROCESS_INTERVAL=3600  # 1 hour in seconds

# Slack Bot
SLACK_BOT_TOKEN=xoxb-your-bot-token-here
SLACK_APP_TOKEN=xapp-your-app-token-here
SLACK_SIGNING_SECRET=your-signing-secret-here
